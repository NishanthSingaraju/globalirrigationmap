{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libary Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import warnings\n",
    "import rasterio as rio\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "from pyhdf.SD import SD, SDC\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "ncores = os.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2010 cropland boundaries - generate Crop mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_dem_path = 'lower_scaled_gfsad.tif'\n",
    "with rio.open(lidar_dem_path) as lidar_dem:\n",
    "    im_array = lidar_dem.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2160, 4320)\n",
      "702138\n"
     ]
    }
   ],
   "source": [
    "print(im_array.shape)\n",
    "# Get a list of cropland and their classes\n",
    "im_array = im_array.reshape((2160,4320))\n",
    "\n",
    "def apply_mask(pixel):\n",
    "    if pixel == 9:\n",
    "        return 0\n",
    "    else:\n",
    "        return pixel\n",
    "\n",
    "filter_function = np.vectorize(apply_mask)\n",
    "unmasked_pixels = filter_function(im_array)\n",
    "\n",
    "land_pixels = np.nonzero(unmasked_pixels) \n",
    "# print(np.unique(imarray))\n",
    "land_pixel_classes = im_array[land_pixels].tolist()\n",
    "print(len(land_pixel_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce Data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(702138, 2)\n"
     ]
    }
   ],
   "source": [
    "land_indices = land_pixels \n",
    "non_zero_indices = np.array(land_indices)\n",
    "clean_frame = non_zero_indices.T\n",
    "print(clean_frame.shape)\n",
    "n = clean_frame.shape[0]\n",
    "non_zeros = np.nonzero(im_array)\n",
    "\n",
    "clean_frame_2 = clean_frame \n",
    "clean_frame_df = pd.DataFrame({'lon': clean_frame[:,0], 'lat': clean_frame[:,1]})\n",
    "clean_frame_df['labels'] = land_pixel_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add siebert labels\n",
    "Each year will take the cropland mask and produce values for the pixel for each year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2160, 4320)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_years = ['1985', '1990', '1995', '2000', '2005']\n",
    "output_years = label_years + [ '2001', '2002', '2003', '2004', '2006','2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015',\n",
    "  '2016', '2017', '2018', '2019']\n",
    "lidar_dem_path = 'C:\\\\Users\\\\Elle\\\\Documents\\\\w210\\\\1985.tif'\n",
    "times_series_labels = np.zeros((5, 2160, 4320))\n",
    "for i in range(len(label_years)):\n",
    "    lidar_dem_path = label_years[i] +'.tif'\n",
    "    with rio.open(lidar_dem_path) as lidar_dem:\n",
    "        array = lidar_dem.read() \n",
    "        array = array.reshape(2160, 4320)\n",
    "        clean_frame_df[str(label_years[i])] = array[land_indices].reshape(n,1)\n",
    "\n",
    "times_series_labels[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve NDVI Data for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = ['max_y1', 'min_y1', 'mean_y1', 'var_y1', 'max_y2', 'min_y2', 'mean_y2', 'var_y2']\n",
    "ndvi_list = os.listdir('ndvi')\n",
    "def retrieve_ndvi(indices, length, year):\n",
    "            path = 'ndvi/ndvi3g_geo_v1_'\n",
    "            file_1h = path + year + '_0106.nc4'\n",
    "            file_2h = path + year + '_0712.nc4' \n",
    "            ds_1, ds_2 = np.array(Dataset(file_1h)['ndvi']) , np.array(Dataset(file_2h)['ndvi'])\n",
    "            max_y1 = np.max(ds_1, axis = 0)[indices].reshape(length)\n",
    "            min_y1 = np.min(ds_1, axis = 0)[indices].reshape(length)\n",
    "            var_y1 = np.var(ds_1, axis = 0)[indices].reshape(length)\n",
    "            mean_y1= np.mean(ds_1, axis = 0)[indices].reshape(length)\n",
    "            max_y2 = np.max(ds_2, axis = 0)[indices].reshape(length)\n",
    "            min_y2 = np.min(ds_2, axis = 0)[indices].reshape(length)\n",
    "            var_y2 = np.var(ds_2, axis = 0)[indices].reshape(length)\n",
    "            mean_y2 = np.mean(ds_2, axis = 0)[indices].reshape(length)\n",
    "            return max_y1, min_y1, mean_y1, var_y1, max_y2, min_y2, mean_y2, var_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndvi_mask(pixel):\n",
    "    if pixel < -1:\n",
    "        return 0\n",
    "    else:\n",
    "        return pixel*10000\n",
    "\n",
    "def ndvi_modis(indices, length, year):\n",
    "    ndvi_frame = np.zeros((23,2160,4320))\n",
    "    file_dir = 'daily_ndvi/processed/' + year + '/'\n",
    "    for i in range(23):\n",
    "        full_path = file_dir + str(i) + '.csv' \n",
    "        ds = pd.read_csv(full_path)\n",
    "        filter_function = np.vectorize(ndvi_mask)\n",
    "        data = filter_function(ds)\n",
    "        data = resize(data, (2160, 4320), preserve_range=True)\n",
    "        ndvi_frame[i,:,:]= data\n",
    "    ds_1, ds_2  = ndvi_frame[0:12,:,:], ndvi_frame[12:,:,:]\n",
    "    max_y1 = np.max(ds_1, axis = 0)[indices].reshape(length)\n",
    "    min_y1 = np.min(ds_1, axis = 0)[indices].reshape(length)\n",
    "    var_y1 = np.var(ds_1, axis = 0)[indices].reshape(length)\n",
    "    mean_y1= np.mean(ds_1, axis = 0)[indices].reshape(length)\n",
    "    max_y2 = np.max(ds_2, axis = 0)[indices].reshape(length)\n",
    "    min_y2 = np.min(ds_2, axis = 0)[indices].reshape(length)\n",
    "    var_y2 = np.var(ds_2, axis = 0)[indices].reshape(length)\n",
    "    mean_y2 = np.mean(ds_2, axis = 0)[indices].reshape(length)\n",
    "    return max_y1, min_y1, mean_y1, var_y1, max_y2, min_y2, mean_y2, var_y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Climate Data for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nc(indices, length, year, variable):\n",
    "    path = 'climate/' + year + '/' + variable + '/'\n",
    "    full_path = path + 'TerraClimate_' + variable +'_' + year + '.nc'\n",
    "    ds = np.array(Dataset(full_path)[variable])\n",
    "    max_y1 = np.max(ds, axis = 0)\n",
    "    min_y1 = np.min(ds, axis = 0)\n",
    "    var_y1 = np.var(ds, axis = 0)\n",
    "    mean_y1 = np.mean(ds, axis = 0)\n",
    "    max_y1 = resize(max_y1, (2160, 4320))[indices].reshape(length)\n",
    "    min_y1 = resize(min_y1, (2160, 4320))[indices].reshape(length)\n",
    "    var_y1 = resize(var_y1, (2160, 4320))[indices].reshape(length)\n",
    "    mean_y1 = resize(mean_y1, (2160, 4320))[indices].reshape(length)\n",
    "    return max_y1, min_y1, var_y1, mean_y1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save each Year to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndvi done for2019\n",
      "climate2019\n"
     ]
    }
   ],
   "source": [
    "def retrieve_year_clim(indices, length, year, ref_df):\n",
    "    measures = ['aet', 'def', 'pet', 'ppt', 'srad', 'tmax', 'tmin', 'vap', 'vpd', 'soil', 'PDSI']\n",
    "    train_years = ['1985', '1990', '1995', '2000', '2005']\n",
    "    \n",
    "    \n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['lat'], new_df['lon']  = ref_df['lat'], ref_df['lon']\n",
    "    \n",
    "    #Add labels - where applicable \n",
    "    if year in train_years:\n",
    "        new_df['label'] = ref_df[year]\n",
    "    \n",
    "    #retrieve ndvi\n",
    "#     if int(year) < 2016:\n",
    "#         #if avhrr is available\n",
    "#         new_df['ndvi_max_y1'], new_df['ndvi_min_y1'], new_df['ndvi_mean_y1'], new_df['ndvi_var_y1'], new_df['ndvi_max_y2'], new_df['ndvi_min_y2'], new_df['ndvi_mean_y2'], new_df['ndvi_var_y2']  = retrieve_ndvi(indices, length, year)\n",
    "#     else:\n",
    "        #else use modis\n",
    "    new_df['ndvi_max_y1'], new_df['ndvi_min_y1'], new_df['ndvi_mean_y1'], new_df['ndvi_var_y1'], new_df['ndvi_max_y2'], new_df['ndvi_min_y2'], new_df['ndvi_mean_y2'], new_df['ndvi_var_y2']  = ndvi_modis(indices, length, year)\n",
    "    print('ndvi done for' + year)\n",
    "    for i in measures:\n",
    "        #retrieve relevant climate variables\n",
    "        new_df[i+'_max'], new_df[i+'_min'], new_df[i+'_var'], new_df[i+'_mean'] = extract_nc(indices, length, year, i)\n",
    "    print('climate' + year)\n",
    "    return new_df\n",
    "\n",
    "for j in ['2019']:\n",
    "    t= retrieve_year_clim(land_indices, n, j , clean_frame_df)\n",
    "    file_save_loc = 'data/new_ndvi/' + j + '.csv'\n",
    "    t.to_csv(file_save_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Long term averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "climate/lt/aet/TerraClimate19812010_aet.nc\n",
      "climate/lt/def/TerraClimate19812010_def.nc\n",
      "climate/lt/pet/TerraClimate19812010_pet.nc\n",
      "climate/lt/ppt/TerraClimate19812010_ppt.nc\n",
      "climate/lt/srad/TerraClimate19812010_srad.nc\n",
      "climate/lt/tmax/TerraClimate19812010_tmax.nc\n",
      "climate/lt/tmin/TerraClimate19812010_tmin.nc\n",
      "climate/lt/vap/TerraClimate19812010_vap.nc\n",
      "climate/lt/vpd/TerraClimate19812010_vpd.nc\n",
      "climate/lt/soil/TerraClimate19812010_soil.nc\n"
     ]
    }
   ],
   "source": [
    "measures_2 = ['aet', 'def', 'pet', 'ppt', 'srad', 'tmax', 'tmin', 'vap', 'vpd', 'soil']  \n",
    "\n",
    "def extract_nc_lt(indices, length, variable):\n",
    "    path = 'climate/lt/' + variable + '/'\n",
    "    full_path = path + 'TerraClimate19812010_' + variable  + '.nc'\n",
    "    print(full_path)\n",
    "    ds = np.array(Dataset(full_path)[variable])\n",
    "    max_y1 = np.max(ds, axis = 0)\n",
    "    min_y1 = np.min(ds, axis = 0)\n",
    "    var_y1 = np.var(ds, axis = 0)\n",
    "    mean_y1= np.mean(ds, axis = 0)\n",
    "    max_y1 = resize(max_y1, (2160, 4320))[indices].reshape(length,1)\n",
    "    min_y1 = resize(min_y1, (2160, 4320))[indices].reshape(length,1)\n",
    "    var_y1 = resize(var_y1, (2160, 4320))[indices].reshape(length,1)\n",
    "    mean_y1 = resize(mean_y1, (2160, 4320))[indices].reshape(length,1)\n",
    "    return max_y1, min_y1, var_y1, mean_y1\n",
    "\n",
    "for i in measures_2:\n",
    "    clean_frame_df[i+'_lt_max'], clean_frame_df[i+'_lt_min'], clean_frame_df[i+'_lt_var'], clean_frame_df[i+'_lt_mean'] = extract_nc_lt(land_indices, n, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_frame = clean_frame_df[['lon', 'lat','aet_lt_max', 'aet_lt_min', 'aet_lt_var', 'aet_lt_mean', 'def_lt_max',\n",
    "       'def_lt_min', 'def_lt_var', 'def_lt_mean', 'pet_lt_max', 'pet_lt_min',\n",
    "       'pet_lt_var', 'pet_lt_mean', 'ppt_lt_max', 'ppt_lt_min', 'ppt_lt_var',\n",
    "       'ppt_lt_mean', 'srad_lt_max', 'srad_lt_min', 'srad_lt_var', 'soil_lt_max', 'soil_lt_min', 'soil_lt_var',\n",
    "       'soil_lt_mean',\n",
    "       'srad_lt_mean', 'tmax_lt_max', 'tmax_lt_min', 'tmax_lt_var',\n",
    "       'tmax_lt_mean', 'tmin_lt_max', 'tmin_lt_min', 'tmin_lt_var',\n",
    "       'tmin_lt_mean', 'vap_lt_max', 'vap_lt_min', 'vap_lt_var', 'vap_lt_mean',\n",
    "       'vpd_lt_max', 'vpd_lt_min', 'vpd_lt_var', 'vpd_lt_mean' ]]\n",
    "lt_frame.to_csv('data/lt.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare NDVI for the same year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/w210-dlvm/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: WARNING: valid_range not used since it\n",
      "cannot be safely cast to variable data type\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "path = 'ndvi/ndvi3g_geo_v1_'\n",
    "file_1h = path + '2015' + '_0106.nc4'\n",
    "ds_3 = np.array(Dataset(file_1h)['ndvi'])\n",
    "max_y3 = np.max(ds_3, axis = 0)[land_indices].reshape(n)\n",
    "min_y3 = np.min(ds_3, axis = 0)[land_indices].reshape(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "HDF4Error",
     "evalue": "SD (15): File is supported, must be either hdf, cdf, netcdf",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHDF4Error\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e0f0ebb4bfa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mndvi_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSDC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0msds_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndvi_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CMG 0.05 Deg 16 days NDVI'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msds_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get sds data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w210-dlvm/lib/python3.7/site-packages/pyhdf/SD.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSDstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         \u001b[0m_checkErr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cannot open %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w210-dlvm/lib/python3.7/site-packages/pyhdf/error.py\u001b[0m in \u001b[0;36m_checkErr\u001b[0;34m(procName, val, msg)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s : %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprocName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHDF4Error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mHDF4Error\u001b[0m: SD (15): File is supported, must be either hdf, cdf, netcdf"
     ]
    }
   ],
   "source": [
    "year = '2015'\n",
    "ndvi_frame = np.zeros((23,2160,4320))\n",
    "file_dir = 'evi/' + year + '/'\n",
    "file_list = os.listdir(file_dir)\n",
    "for i in range(len(file_list)):\n",
    "    ndvi_file = SD(file_dir + file_list[i], SDC.READ)\n",
    "    sds_obj = ndvi_file.select('CMG 0.05 Deg 16 days NDVI') \n",
    "    data = np.array(sds_obj.get()) # get sds data\n",
    "    data = resize(data, (2160, 4320), preserve_range=True)\n",
    "    ndvi_frame[i,:,:]= data\n",
    "    ds_1, ds_2  = ndvi_frame[0:12,:,:], ndvi_frame[12:,:,:]\n",
    "    max_y1 = np.max(ds_1, axis = 0)[land_indices].reshape(n)\n",
    "    min_y1 = np.min(ds_1, axis = 0)[land_indices].reshape(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min_y1.mean())\n",
    "print(min_y3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
